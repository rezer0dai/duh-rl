ENV = "mujoco-reach"
SEED = 0
MAX_TIMESTEPS = 1e6
# TD3
EXPL_NOISE = 0.1
BATCH_SIZE = 256
DISCOUNT = 0.982
TAU = 0.005
POLICY_NOISE = 0.2
NOISE_CLIP = 0.5
POLICY_FREQ = 2
# TD3 + BC
ALPHA = 2.5
NORMALIZE = False
# OPEN AI TD3 BASELINE TRAINING
EPOCHS = 60
REPLAY_SIZE = 1e7
START_STEPS = 10000
UPDATE_AFTER = 1000
UPDATE_EVERY = 50*2
UPDATE_COUNT = 40
EVAL_FREQ = 50 * UPDATE_EVERY
# HER
HER_PER_EP = 10
HER_RATIO = .75
# PPO
STEPS_PER_EPOCH = 2000
MINI_BATCH_SIZE = 32
PPO_EPOCHS_PER_UPDATE = 20
PPO_DELAY_LEARN = 1000

RPOLYAK=True
KL_MIN = 0.001
HINDSIGHT_ACTION=0.3
TD3_GAE = False
CRITIC_EMPHATIZE_RECENT = True
PPO_GAE_N = 3
TD3_GAE_N = 1
PPO_HER = True#False
D2RL = True
PPO_NORM_IN = True
PPO_TRAIN_ACTOR = False
PPO_TRAIN_CRITIC = True


#DLPPOH
TIMEFEAT = False#True#
LEAK2LL = True#False#

# AUXILARY
CLIP_Q = False#True
PIL2_GV = True

PANDA = "panda" in ENV
ERGOJR = "ergojr" in ENV
MUJOCO = not PANDA and not ERGOJR
assert MUJOCO + PANDA + ERGOJR == 1

BACKLASH = False
PUSHER = "usher" in ENV

GOAL_SIZE = 3

if ERGOJR: # no gripper, velo per joint ( #of joints == action_size )
    ACTION_SIZE = 3 + (not PUSHER) * 1#3
    LL_STATE_SIZE = GOAL_SIZE * 2 + ACTION_SIZE * 2 + TIMEFEAT
    STATE_SIZE = GOAL_SIZE + LL_STATE_SIZE + 3*GOAL_SIZE*PUSHER
else: # arm pos, arm prev pos, arm velo, gripper pos + velo + velp
    ACTION_SIZE = 3 + MUJOCO
    LL_STATE_SIZE = GOAL_SIZE * 3 + 4 * MUJOCO + TIMEFEAT
    STATE_SIZE = 2*GOAL_SIZE + LL_STATE_SIZE + 6*GOAL_SIZE*PUSHER# velp + gripper, object velp for pusher

GOAL0_SIZE = GOAL_SIZE
GOAL1_SIZE = 20

HRL = True
ACHIEVED_PUSH_N = 2

ADVANTAGE = False
ADV_NORM = False

REW_DELTA = 1.0
REW_SCALE = 1.0
KL_DELTA = 1.0
KL_SCALE = 1.0

LOOKAHEAD_1 = 0.5
LOOKAHEAD_K = 0.5
SEPERATE_CRITICS = False

PPO_HER_RATIO = 0.33
BLIND = True

TD3_PPO_GRADS = True
TD3_PPO_CLIP = True
